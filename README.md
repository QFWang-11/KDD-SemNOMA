# Knowledge Distillation Driven Semantic NOMA for Image Transmission with Diffusion Model

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

A research project on **Semantic Non-Orthogonal Multiple Access with Knowledge Distillation and Diffusion Model** for efficient multi-user semantic communication systems.

## ğŸ“– Overview

This repository implements a novel semantic communication framework that combines **Knowledge Distillation (KD)** and **Diffusion Model** for Non-Orthogonal Multiple Access (NOMA) transmisstion. 

### Key Innovations
- ğŸ§  **Knowledge Distillation Framework**: Teacher-student architecture for semantic feature extraction
- ğŸ“¡ **Semantic NOMA**: Non-orthogonal multiple access with semantic information
- ğŸ”„ **Diffusion Model Integration**: Advanced image reconstruction using diffusion models
- ğŸ“Š **Multi-Channel Support**: AWGN and Rayleigh fading channel models

## ğŸ—ï¸ Architecture Overview

The system architecture consists of:

1. **Semantic Encoder**: Extracts semantic features from input data
2. **Knowledge Distillation Module**: Transfers knowledge from teacher to student networks
3. **NOMA Transmitter**: Encodes multiple users' data using NOMA principles
4. **Channel Layer**: Simulates realistic wireless channel conditions
5. **NOMA Receiver**: Decodes multi-user signals with interference cancellation
6. **Semantic Decoder**: Reconstructs original data from semantic features
7. **Diffusion Model**: Refine the received images

## ğŸ“ Project Structure

```
KDD-SemNOMA/
â”œâ”€â”€ ğŸ“„ images/                         # Figures
â”‚   â”œâ”€â”€ KD-SemNOMA.pdf               
â”‚   â””â”€â”€ KDD-SemNOMA.pdf              
â”œâ”€â”€ ğŸ§  kd_semnoma/                  # Core KD-SemNOMA implementation
â”‚   â”œâ”€â”€ models/                     # Neural network models
â”‚   â”‚   â”œâ”€â”€ SemNOMA.py              # Basic SemNOMA model
â”‚   â”‚   â”œâ”€â”€ SemNOMA_with_KD.py      # KD-enhanced SemNOMA
â”‚   â”‚   â”œâ”€â”€ Teacher_Model.py        # Teacher network
â”‚   â”‚   â”œâ”€â”€ autoencoder.py          # Autoencoder architectures
â”‚   â”‚   â”œâ”€â”€ kd_loss.py              # Knowledge distillation losses
â”‚   â”‚   â”œâ”€â”€ baseline.py             # Baseline models
â”‚   â”‚   â”œâ”€â”€ channel.py              # Channel modeling
â”‚   â”‚   â”œâ”€â”€ layers.py               # Custom neural layers
â”‚   â”‚   â”œâ”€â”€ losses.py               # Loss functions
â”‚   â”‚   â””â”€â”€ power_constraint.py     # Power control utilities
â”‚   â”œâ”€â”€ datasets/                   # Dataset processing
â”‚   â”‚   â”œâ”€â”€ cifar10_group_wrapper.py  # CIFAR-10 handler
â”‚   â”‚   â””â”€â”€ ffhq256_group_wrapper.py  # FFHQ-256 handler
â”‚   â”œâ”€â”€ train_baseline.py           # Baseline training
â”‚   â”œâ”€â”€ train_semnoma.py            # SemNOMA training
â”‚   â”œâ”€â”€ train_teacher_model.py      # Teacher model training
â”‚   â”œâ”€â”€ train_student_model.py      # Student model training (KD)
â”‚   â””â”€â”€ test.py                     # Model testing
â””â”€â”€ ğŸš€ kdd_semnoma/                 # Advanced KDD-SemNOMA
    â”œâ”€â”€ kdd_semnoma/                # Enhanced implementation
    â”‚   â”œâ”€â”€ sampler.py              # Diffusion model sampling
    â”‚   â”œâ”€â”€ calculate_metrics.py    # Performance metrics
    â”‚   â”œâ”€â”€ inference_difface.py    # inference
    â”‚   â””â”€â”€ basicsr/                # Image quality metrics
    â””â”€â”€ semnoma_cgan/               # Conditional GAN implementation
        â”œâ”€â”€ Acnet_gan.py            # SemNOMA-CGAN architecture
        â””â”€â”€ eval_ACGAN.py           # SemNOMA-CGAN evaluation
```

## âœ¨ Key Features

### ğŸ”¬ Model Architecture
- **Knowledge Distillation**: Teacher-student framework with cross-layer feature matching
- **Semantic Communication**: Efficient transmission of semantic information rather than raw data
- **NOMA Technology**: Non-orthogonal multiple access for improved spectral efficiency
- **Diffusion Models**: State-of-the-art image reconstruction capabilities

### ğŸ“¡ Channel Models
| Channel Type | Model Class | Description |
|--------------|-------------|-------------|
| AWGN | [`SemNOMA_KD_AWGN`](kd_semnoma/models/SemNOMA_with_KD.py) | Additive White Gaussian Noise |
| Rayleigh | [`SemNOMA_KD_Rayleigh`](kd_semnoma/models/SemNOMA_with_KD.py) | Rayleigh Fading Channel |

### ğŸ“Š Supported Datasets
| Dataset | Resolution | Wrapper |
|---------|------------|---------|
| CIFAR-10 | 32Ã—32 |[`cifar10_group_wrapper.py`](kd_semnoma/datasets/cifar10_group_wrapper.py) |
| FFHQ-256 | 256Ã—256 | [`ffhq256_group_wrapper.py`](kd_semnoma/datasets/ffhq256_group_wrapper.py) |

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

```bash
# Minimum requirements
Python >= 3.8
CUDA >= 11.0 (for GPU acceleration)
```

### ğŸ”§ Installation

```bash
# Clone the repository
git clone https://github.com/your-username/KDD-SemNOMA.git
cd KDD-SemNOMA

# Create virtual environment (recommended)
python -m venv kdd_env
source kdd_env/bin/activate  # On Windows: kdd_env\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Verify installation
python -c "import torch; print(f'PyTorch version: {torch.__version__}')"
```

### ğŸƒâ€â™‚ï¸ Training Pipeline

#### 1ï¸âƒ£ Train Teacher Model
```bash
python kd_semnoma/train_teacher_model.py
```

#### 2ï¸âƒ£ Train Student Model with Knowledge Distillation
```bash
python kd_semnoma/train_student_model.py
```

#### 3ï¸âƒ£ Train SemNOMA System without Knowledge Distillation (for comparison)
```bash
python kd_semnoma/train_semnoma.py
```

#### 4ï¸âƒ£ Train Baseline Models (for comparison)
```bash
python kd_semnoma/train_baseline.py
```

### ğŸ§ª Testing and Evaluation

#### ğŸ” Basic Model Testing (SemNOMA/KD-SemNOMA)
```bash
python kd_semnoma/test.py
```

#### ğŸ“¡ SemNOMA-CGAN Evaluation
```bash
python kdd_semnoma/semnoma_cgan/eval_ACGAN.py \
    --ckptdir ./checkpoints \
    --net_G unet_256 \
    --dataset ffhq256
```

#### ğŸ“ˆ KDD-SemNOMA Evaluation
```bash
python kdd_semnoma/kdd_semnoma/inference_difface.py \
    --in_path ./testdata \
    --out_path ./results/diffusion \
    --task restoration \
    --eta 0.5
```

## ğŸ“Š Evaluation Metrics

The framework supports comprehensive evaluation using multiple metrics:

### ğŸ–¼ï¸ Image Quality Metrics
| Metric | Description | Range | Better |
|--------|-------------|--------|--------|
| **PSNR** | Peak Signal-to-Noise Ratio | [0, âˆ) dB | Higher |
| **SSIM** | Structural Similarity Index | [0, 1] | Higher |
| **LPIPS** | Learned Perceptual Image Patch Similarity | [0, âˆ) | Lower |
| **FID** | FrÃ©chet Inception Distance | [0, âˆ) | Lower |


## ğŸ”¬ Research Background

### ğŸŒ Semantic NOMA Architecture

![KDD-SemNOMA Architecture](images\SemNOMA.jpg)

Our innovative approach combines semantic communication with NOMA:

- **Semantic Encoding**: Extract task-relevant features instead of raw data
- **Adaptative Channel Feature Encoding**: Adaptative AWGN/Rayleigh Channel Feature Encoding
- **Joint Optimization**: End-to-end learning for optimal performance

### ğŸ“š Knowledge Distillation in Semantic Communication

![KDD-SemNOMA Architecture](images\KD-SemNOMA.jpg)

Knowledge Distillation enables efficient knowledge transfer from complex teacher networks to lightweight student networks:

- **Teacher Network**: High-capacity model trained for optimal feature extraction
- **Student Network**: Efficient model deployed at the transmitter
- **Knowledge Transfer**: Cross-layer feature matching and soft target learning
- **Benefits**: Reduced complexity while maintaining performance

### âœ¨ Diffusion Model Enhancement

![KDD-SemNOMA Architecture](images\KDD-SemNOMA.jpg)

Diffusion models provide superior image reconstruction:

- **High Quality**: State-of-the-art generative capabilities
- **Iterative Refinement**: Gradual denoising process
- **Conditional Generation**: Task-specific image enhancement
- **Real-time Inference**: Optimized for practical deployment

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on how to submit pull requests, report issues, and contribute to the project.

## ğŸ™ Acknowledgments

- Thanks to the PyTorch team for the excellent deep learning framework
- The wireless communication community for foundational NOMA research
- Some codes are brought from [DifFace](https://github.com/zsyOAOA/DifFace/), [CrossKD](https://github.com/jbwang1997/CrossKD). Thanks for their awesome works.

## ğŸ“ Contact

- **Email**: wqfneubit@163.com
---

<div align="center">
  <sub>Built with â¤ï¸ for advancing semantic communication research</sub>
</div>